{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4afa811-915b-4d89-9216-a5b0e44c9bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_datareader.data as pdr\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca5ffc-e052-459f-ad9b-20ffc8f3710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "START_DATE = '1990-01-01'  # Start date for fetching data\n",
    "END_DATE = '2022-01-01'    # End date for fetching data\n",
    "EXPORT_PATH = '/home/student/suahmad/Richter_Final/Main_files/'  # Directory to save the output CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ec489-1841-48ad-b9bc-7fdb42790209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch macroeconomic data from FRED\n",
    "def fetch_macro_data():\n",
    "    # GDP data\n",
    "    gdp = pdr.DataReader('GDP', 'fred', START_DATE, END_DATE)\n",
    "    \n",
    "    # Unemployment rate data\n",
    "    unemployment = pdr.DataReader('UNRATE', 'fred', START_DATE, END_DATE)\n",
    "    unemployment.rename(columns={'UNRATE': 'Unemployment_Rate'}, inplace=True)\n",
    "    \n",
    "    # USD to Euro exchange rate\n",
    "    exchange = pdr.DataReader('DEXUSEU', 'fred', START_DATE, END_DATE)\n",
    "    exchange.rename(columns={'DEXUSEU': 'Exchange_Rate(USD to Euro)'}, inplace=True)\n",
    "    \n",
    "    # Federal funds rate\n",
    "    fed_funds = pdr.DataReader('FEDFUNDS', 'fred', START_DATE, END_DATE)\n",
    "    fed_funds.rename(columns={'FEDFUNDS': 'Federal_Funds_Rate'}, inplace=True)\n",
    "\n",
    "    # Combine all macroeconomic indicators into one DataFrame\n",
    "    data = gdp.join([unemployment, exchange, fed_funds], how='outer')\n",
    "    data.reset_index(inplace=True)\n",
    "    data['DATE'] = pd.to_datetime(data['DATE']).dt.tz_localize(None)  # Remove timezone info\n",
    "\n",
    "    # Forward fill missing values for critical indicators\n",
    "    data['GDP'] = data['GDP'].ffill()\n",
    "    data['Federal_Funds_Rate'] = data['Federal_Funds_Rate'].ffill()\n",
    "    data['Unemployment_Rate'] = data['Unemployment_Rate'].ffill()\n",
    "\n",
    "    return data\n",
    "\n",
    "# Function to fetch VIX (volatility index) data using yfinance\n",
    "def fetch_vix_data():\n",
    "    ticker = yf.Ticker('^VIX')\n",
    "    vix = ticker.history(start=START_DATE, end=END_DATE)[['Close']]\n",
    "    vix.reset_index(inplace=True)\n",
    "    vix.rename(columns={'Date': 'DATE', 'Close': 'VIX'}, inplace=True)\n",
    "    vix['DATE'] = pd.to_datetime(vix['DATE']).dt.tz_localize(None)  # Remove timezone info\n",
    "    return vix\n",
    "\n",
    "# Function to fetch historical stock data for a given ticker symbol\n",
    "def fetch_stock_data(ticker_symbol):\n",
    "    ticker = yf.Ticker(ticker_symbol)\n",
    "    df = ticker.history(start=START_DATE, end=END_DATE)[['Close']]\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'Date': 'DATE', 'Close': 'Close_Price'}, inplace=True)\n",
    "    df['DATE'] = pd.to_datetime(df['DATE']).dt.tz_localize(None)  # Remove timezone info\n",
    "    return df\n",
    "\n",
    "# Function to compile macro, VIX, and stock data into a single DataFrame\n",
    "def compile_data(ticker_symbol):\n",
    "    macro = fetch_macro_data()\n",
    "    vix = fetch_vix_data()\n",
    "    stock = fetch_stock_data(ticker_symbol)\n",
    "\n",
    "    # Merge datasets on DATE\n",
    "    df = macro.merge(vix, on='DATE', how='outer')\n",
    "    df = df.merge(stock, on='DATE', how='outer')\n",
    "    return df\n",
    "\n",
    "# Function to remove rows with any missing (NA) values\n",
    "def remove_na_values(df):\n",
    "    df_cleaned = df.dropna()\n",
    "    return df_cleaned\n",
    "\n",
    "# Function to compile data for a stock ticker and save it as a CSV file\n",
    "def save_data_for_ticker(ticker_symbol):\n",
    "    df = compile_data(ticker_symbol)\n",
    "    df = remove_na_values(df)\n",
    "    file_path = f\"{EXPORT_PATH}{ticker_symbol}_combined.csv\"\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"âœ… File saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428adb9a-1d48-4bbd-9adc-a71cf3b3760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for all tickers\n",
    "tickers = ['LLY', 'UNH', 'JNJ','ABBV','ABT','MRK','TMO','ISRG','GILD','CVS','CI','BIIB','REGN','VRTX','DHR','MCK','BMY','PFE','AMGN']\n",
    "\n",
    "for ticker in tickers:\n",
    "    save_data_for_ticker(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eab0f1-7d07-453d-9124-a91ad5ce155c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
